\chapter{Estimation}
\label{sec-9}

\noindent
We will discuss two branches of estimation procedures: point
estimation and interval estimation. We briefly discuss point
estimation first and then spend the rest of the chapter on interval
estimation.

We find an estimator with the methods of Section
\ref{sec-9-1}. We make some assumptions about the
underlying population distribution and use what we know from Chapter
\ref{sec-8} about sampling
distributions both to study how the estimator will perform, and to
find intervals of confidence for underlying parameters associated with
the population distribution. Once we have confidence intervals we can
do inference in the form of hypothesis tests in the next chapter.

\textbf{What do I want them to know?}
\begin{itemize}
\item how to look at a problem, identify a reasonable model, and estimate
a parameter associated with the model
\item about maximum likelihood, and in particular, how to
\begin{itemize}
\item eyeball a likelihood to get a maximum
\item use calculus to find an MLE for one-parameter families
\end{itemize}
\item about properties of the estimators they find, such as bias, minimum
variance, MSE
\item point versus interval estimation, and how to find and interpret
confidence intervals for basic experimental designs
\item the concept of margin of error and its relationship to sample size
\end{itemize}

\section{Point Estimation}
\label{sec-9-1}

The following example is how I was introduced to maximum likelihood.

\label{exa-how-many-fish} Suppose we have a small pond in our backyard,
and in the pond there live some fish. We would like to know how many
fish live in the pond. How can we estimate this? One procedure
developed by researchers is the capture-recapture method. Here is how
it works.

We will fish from the pond and suppose that we capture \(M=7\)
fish. On each caught fish we attach an unobtrusive tag to the fish's
tail, and release it back into the water.

Next, we wait a few days for the fish to remix and become accustomed
to their new tag. Then we go fishing again. On the second trip some of
the fish we catch may be tagged; some may not be. Let \(X\) denote the
number of caught fish which are tagged, and suppose
for the sake of argument that we catch \(K=4\) fish and we find that 3
of them are tagged.

\label{exa-bass-bluegill} In the last example we were only concerned with
how many fish were in the pond, but now, we will ask a different
question. Suppose it is known that there are only two species of fish
in the pond: smallmouth bass (\emph{Micropterus dolomieu}) and bluegill
(\emph{Lepomis macrochirus}); perhaps we built the pond some years ago and
stocked it with only these two species. We would like to estimate the
proportion of fish in the pond which are bass.

Let \(p=\mbox{the proportion of bass}\). Without any other
information, it is conceivable for \(p\) to be any value in the
interval \([0,1]\), but for the sake of argument we will suppose that
\(p\) falls strictly between zero and one. How can we learn about the
true value of \(p\)? Go fishing! As before, we will use
catch-and-release, but unlike before, we will not tag the fish. We
will simply note the species of any caught fish before returning it to
the pond.

Suppose we catch \(n\) fish. Let \[ X_{i} = \begin{cases} 1, &
\mbox{if the \(i\mathrm{th}\) fish is a bass,}\\ 0, & \mbox{if the
\(i\mathrm{th}\) fish is a bluegill.} \end{cases} \] Since we are
returning the fish to the pond once caught, we may think of this as a
sampling scheme with replacement where the proportion of bass \(p\)
does not change. Given that we allow the fish sufficient time to "mix"
once returned, it is not completely unreasonable to model our fishing
experiment as a sequence of Bernoulli trials, so that the \(X_{i}\)'s
would be IID
\(\mathsf{binom(\mathtt{size}}=1,\,\mathtt{prob}=p)\). Under those
assumptions we would have
\begin{eqnarray*}
\mathbb{P}(X_{1}=x_{1},\, X_{2}=x_{2},\,\ldots,\, X_{n}=x_{n}) & = & \mathbb{P}(X_{1}=x_{1})\,\mathbb{P}(X_{2}=x_{2})\,\cdots\mathbb{P}(X_{n}=x_{n}),\\
 & = & p^{x_{1}}(1-p)^{x_{1}}\, p^{x_{2}}(1-p)^{x_{2}}\cdots\, p^{x_{n}}(1-p)^{x_{n}},\\
 & = & p^{\sum x_{i}}(1-p)^{n-\sum x_{i}}.
\end{eqnarray*}
That is, \[ \mathbb{P}(X_{1}=x_{1},\, X_{2}=x_{2},\,\ldots,\,
X_{n}=x_{n})=p^{\sum x_{i}}(1-p)^{n-\sum x_{i}}.  \] This last
quantity is a function of \(p\), called the \emph{likelihood function}
\(L(p)\): \[ L(p)=p^{\sum x_{i}}(1-p)^{n-\sum x_{i}}.  \] A graph of
\(L\) for values of \(\sum x_{i}=3,\ 4\), and 5 when \(n=7\) is shown
in Figure \ref{fig-fishing-part-two}.

\begin{figure}[ht!]
\centering
\includegraphics[width=0.9\textwidth]{fig/estimate-fishing-part-two.ps}
\caption[Assorted likelihood functions for fishing, part two]{\label{fig-fishing-part-two}\small Assorted likelihood functions for fishing, part two.   Three graphs are shown of \(L\) when \(\sum x_{i}\) equals 3, 4, and 5, respectively, from left to right. We pick an \(L\) that matches the observed data and then maximize \(L\) as a function of \(p\). If \(\sum x_{i}=4\), then the maximum appears to occur somewhere around \(p \approx 0.6\).}
\end{figure}


We want the value of \(p\) which has the highest likelihood, that is,
we again wish to maximize the likelihood. We know from calculus (see
Appendix \ref{sec-21-2}) to differentiate \(L\)
and set \(L'=0\) to find a maximum.  \[ L'(p)=\left(\sum
x_{i}\right)p^{\sum x_{i}-1}(1-p)^{n-\sum x_{i}}+p^{\sum
x_{i}}\left(n-\sum x_{i}\right)(1-p)^{n-\sum x_{i}-1}(-1).  \] The
derivative vanishes (\(L'=0\)) when
\begin{eqnarray*}
\left(\sum x_{i}\right)p^{\sum x_{i}-1}(1-p)^{n-\sum x_{i}} & = & p^{\sum x_{i}}\left(n-\sum x_{i}\right)(1-p)^{n-\sum x_{i}-1},\\
\sum x_{i}(1-p) & = & \left(n-\sum x_{i}\right)p,\\
\sum x_{i}-p\sum x_{i} & = & np-p\sum x_{i},\\
\frac{1}{n}\sum_{i=1}^{n}x_{i} & = & p.
\end{eqnarray*}
This "best" \(p\), the one which maximizes the likelihood, is called
the maximum likelihood estimator (MLE) of \(p\) and is denoted
\(\hat{p}\). That is,
\begin{equation} 
\hat{p}=\frac{\sum_{i=1}^{n}x_{i}}{n}=\overline{x}.
\end{equation}

\begin{rem}
Strictly speaking we have only shown that the derivative equals zero
at \(\hat{p}\), so it is theoretically possible that the critical
value \(\hat{p}=\overline{x}\) is located at a minimum
instead of a maximum! We should be thorough and check that \(L'>0\)
when \(p<\overline{x}\) and \(L'<0\) when \(p>\overline{x}\). Then by
the First Derivative Test (Theorem \ref{thm-First-Derivative-Test}) we could
be certain that \(\hat{p}=\overline{x}\) is indeed a maximum
likelihood estimator, and not a minimum likelihood estimator.
\end{rem}

The result is shown in Figure \texttt{fig-species-mle}.

One of the most common questions in an introductory statistics class
is, "Why do we divide by \(n-1\) when we compute the sample variance?
Why do we not divide by \(n\)?" We see now that division by \(n\)
amounts to the use of a \emph{biased} estimator for \(\sigma^{2}\), that
is, if we divided by \(n\) then on the average we would
\emph{underestimate} the true value of \(\sigma^{2}\). We use \(n-1\) so
that, on the average, our estimator of \(\sigma^{2}\) will be exactly
right.

\subsection{How to do it with \(\mathsf{R}\)}
\label{sec-9-1-1}

\(\mathsf{R}\) can be used to find maximum likelihood estimators in a
lot of diverse settings. We will discuss only the most basic here and
will leave the rest to more sophisticated texts.

For one parameter estimation problems we may use the \texttt{optimize}
function to find MLEs. The arguments are the function to be maximized
(the likelihood function), the range over which the optimization is to
take place, and optionally any other arguments to be passed to the
likelihood if needed.

Let us see how to do Example \ref{exa-bass-bluegill}. Recall that our
likelihood function was given by
\begin{equation}
L(p)=p^{\sum x_{i}}(1-p)^{n-\sum x_{i}}.
\end{equation}
Notice that the likelihood is just a product of
\(\mathsf{binom}(\mathtt{size}=1,\,\mathtt{prob}=p)\) PMFs. We first
give some sample data (in the vector \texttt{datavals}), next we define the
likelihood function \texttt{L}, and finally we \texttt{optimize} \texttt{L} over the range
\texttt{c(0,1)}.

\begin{verbatim}
x <- mtcars$am
L <- function(p,x) prod(dbinom(x, size = 1, prob = p))
optimize(L, interval = c(0,1), x = x, maximum = TRUE)
\end{verbatim}

\begin{verbatim}
: $maximum
: [1] 0.4062458
: 
: $objective
: [1] 4.099989e-10
\end{verbatim}

Note that the \texttt{optimize} function by default minimizes the function
\texttt{L}, so we have to set \texttt{maximum = TRUE} to get an MLE. The returned
value of \texttt{\$maximum} gives an approximate value of the MLE to be
0.406 and \texttt{objective} gives \texttt{L} evaluated at the
MLE which is approximately 0.

We previously remarked that it is usually more numerically convenient
to maximize the log-likelihood (or minimize the negative
log-likelihood), and we can just as easily do this with
\(\mathsf{R}\). We just need to calculate the log-likelihood
beforehand which (for this example) is \[ -l(p)=-\sum x_{i}\ln\,
p-\left(n-\sum x_{i}\right)\ln(1-p).  \]

It is done in \(\mathsf{R}\) with

\begin{verbatim}
minuslogL <- function(p,x){
                -sum(dbinom(x, size = 1, prob = p, log = TRUE))
             }
optimize(minuslogL, interval = c(0,1), x = x)
\end{verbatim}

\begin{verbatim}
: $minimum
: [1] 0.4062525
: 
: $objective
: [1] 21.61487
\end{verbatim}

Note that we did not need \texttt{maximum = TRUE} because we minimized the
negative log-likelihood. The answer for the MLE is essentially the
same as before, but the \texttt{\$objective} value was different, of course.

For multiparameter problems we may use a similar approach by way of
the \texttt{mle} function in the \texttt{stats4} package \cite{stats4}.



\textbf{Plant Growth.} We will investigate the \texttt{weight} variable of the
\texttt{PlantGrowth} data. We will suppose that the weights constitute a
random observations \(X_{1}\), \(X_{2}\), \ldots{} , \(X_{n}\) that are IID
\(\mathsf{norm}(\mathtt{mean}=\mu,\,\mathtt{sd}=\sigma)\) which is not
unreasonable based on a histogram and other exploratory measures. We
will find the MLE of \(\theta=(\mu,\sigma^{2})\). We claimed in
Example \texttt{exa-normal-MLE-both} that
\(\hat{\theta}=(\hat{\mu},\hat{\sigma}^{2})\) had the form given
above. Let us check whether this is plausible numerically. The
negative log-likelihood function is

\begin{verbatim}
minuslogL <- function(mu, sigma2){
  -sum(dnorm(x, mean = mu, sd = sqrt(sigma2), log = TRUE))
}
\end{verbatim}

Note that we omitted the data as an argument to the log-likelihood
function; the only arguments were the parameters over which the
maximization is to take place. Now we will simulate some data and find
the MLE. The optimization algorithm requires starting values
(intelligent guesses) for the parameters. We choose values close to
the sample mean and variance (which turn out to be approximately 5 and
0.5, respectively) to illustrate the procedure.

\begin{verbatim}
x <- PlantGrowth$weight
MaxLikeEst <- mle(minuslogL, start = list(mu = 5, sigma2 = 0.5))
summary(MaxLikeEst)
\end{verbatim}

\begin{verbatim}
Maximum likelihood estimation

Call:
mle(minuslogl = minuslogL, start = list(mu = 5, sigma2 = 0.5))

Coefficients:
        Estimate Std. Error
mu     5.0729848  0.1258666
sigma2 0.4752721  0.1227108

-2 log L: 62.82084
\end{verbatim}

The outputted MLEs are shown above, and \texttt{mle} even gives us estimates
for the standard errors of \(\hat{\mu}\) and \(\hat{\sigma}^{2}\)
(which were obtained by inverting the numerical Hessian matrix at the
optima; see Appendix \ref{sec-21-6}). Let us check how close
the numerical MLEs came to the theoretical MLEs:

\begin{verbatim}
mean(x); var(x)*29/30; sd(x)/sqrt(30)
\end{verbatim}

\begin{verbatim}
: [1] 5.073
: [1] 0.475281
: [1] 0.1280195
\end{verbatim}

The numerical MLEs were very close to the theoretical MLEs. We already
knew that the standard error of \(\hat{\mu}=\overline{X}\) is
\(\sigma/\sqrt{n}\), and the numerical estimate of this was very close
too.



There is functionality in the \texttt{distrTest} package \cite{distrTest} to
calculate theoretical MLEs; we will skip examples of these for the
time being.

\section{Confidence Intervals for Means}
\label{sec-9-2}

We are given \(X_{1}\), \(X_{2}\), \ldots{}, \(X_{n}\) that are an
\(SRS(n)\) from a
\(\mathsf{norm}(\mathtt{mean}=\mu,\,\mathtt{sd}=\sigma)\)
distribution, where \(\mu\) is unknown. We know that we may estimate
\(\mu\) with \(\overline{X}\), and we have seen that this estimator is
the MLE. But how good is our estimate? We know that
\begin{equation} 
\frac{\overline{X}-\mu}{\sigma/\sqrt{n}}\sim\mathsf{norm}(\mathtt{mean}=0,\,\mathtt{sd}=1).
\end{equation}
For a big probability \(1-\alpha\), for instance, 95\%, we can
calculate the quantile \(z_{\alpha/2}\). Then
\begin{equation}
\mathbb{P}\left(-z_{\alpha/2}\leq\frac{\overline{X}-\mu}{\sigma/\sqrt{n}}\leq z_{\alpha/2}\right)=1-\alpha.
\end{equation}
But now consider the following string of equivalent inequalities:
\[
-z_{\alpha/2}\leq\frac{\overline{X}-\mu}{\sigma/\sqrt{n}}\leq z_{\alpha/2},
\]
\[
-z_{\alpha/2}\left(\frac{\sigma}{\sqrt{n}}\right)\leq\overline{X}-\mu\leq z_{\alpha/2}\left(\frac{\sigma}{\sqrt{n}}\right),
\]
\[
-\overline{X} - z_{\alpha/2}\left(\frac{\sigma}{\sqrt{n}}\right)\leq - \mu \leq - \overline{X} + z_{\alpha/2} \left( \frac{\sigma}{\sqrt{n}} \right),
\]
\[
\overline{X} - z_{\alpha/2} \left( \frac{\sigma}{\sqrt{n}} \right) \leq \mu \leq \overline{X} + z_{\alpha/2} \left( \frac{\sigma}{\sqrt{n}} \right).
\]
That is, 
\begin{equation}
\mathbb{P}\left(\overline{X}-z_{\alpha/2}\frac{\sigma}{\sqrt{n}}\leq\mu\leq\overline{X}+z_{\alpha/2}\frac{\sigma}{\sqrt{n}}\right)=1-\alpha.
\end{equation}

\begin{defn}
The interval
\begin{equation}
\left[\overline{X}-z_{\alpha/2}\frac{\sigma}{\sqrt{n}},\ \overline{X}+z_{\alpha/2}\frac{\sigma}{\sqrt{n}}\right]
\end{equation}
is a \(100(1-\alpha)\%\) \emph{confidence interval for} \(\mu\). The quantity \(1-\alpha\) is called the \emph{confidence coefficient}.
\end{defn}

\begin{rem}
The interval is also sometimes written more compactly as
\begin{equation}
\label{eq-z-interval}
\overline{X}\pm z_{\alpha/2}\frac{\sigma}{\sqrt{n}}.
\end{equation}
\end{rem}

The interpretation of confidence intervals is tricky and often
mistaken by novices. When I am teaching the concept "live" during
class, I usually ask the students to imagine that my piece of chalk
represents the "unknown" parameter, and I lay it down on the desk in
front of me. Once the chalk has been lain, it is \emph{fixed}; it does not
move. Our goal is to estimate the parameter. For the estimator I pick
up a sheet of loose paper lying nearby. The estimation procedure is to
randomly drop the piece of paper from above, and observe where it
lands. If the piece of paper covers the piece of chalk, then we are
successful -- our estimator covers the parameter. If it falls off to
one side or the other, then we are unsuccessful; our interval fails to
cover the parameter.

Then I ask them: suppose we were to repeat this procedure hundreds,
thousands, millions of times. Suppose we kept track of how many times
we covered and how many times we did not. What percentage of the time
would we be successful?

In the demonstration, the parameter corresponds to the chalk, the
sheet of paper corresponds to the confidence interval, and the random
experiment corresponds to dropping the sheet of paper. The percentage
of the time that we are successful \emph{exactly} corresponds to the
\emph{confidence coefficient}. That is, if we use a 95\% confidence
interval, then we can say that, in the long run, approximately 95\% of
our intervals will cover the true parameter (which is fixed, but
unknown).

See Figure \ref{fig-ci-examp}, which is a graphical display of these ideas.

\begin{verbatim}
ci.examp()
\end{verbatim}

\begin{figure}[ht!]
\centering
\includegraphics[width=0.9\textwidth]{fig/hypoth-ci-examp.ps}
\caption[Simulated confidence intervals]{\label{fig-ci-examp}\small The graph was generated by the \texttt{ci.examp} function from the \texttt{TeachingDemos} package. Fifty (50) samples of size twenty five (25) were generated from a \( \mathsf{norm}(\mathtt{mean}=100,\,\mathtt{sd}=10) \) distribution, and each sample was used to find a 95\% confidence interval for the population mean using Equation \eqref{eq-z-interval}. The 50 confidence intervals are represented above by horizontal lines, and the respective sample means are denoted by vertical slashes. Confidence intervals that "cover" the true mean value of 100 are plotted in black; those that fail to cover are plotted in a lighter color. In the plot we see that only one (1) of the simulated intervals out of the 50 failed to cover \(\mu=100\), which is a success rate of 98\%. If the number of generated samples were to increase from 50 to 500 to 50000, \ldots{}, then we would expect our success rate to approach the exact value of 95\%.}
\end{figure}

Under the above framework, we can reason that an "interval" with a
\emph{larger} confidence coefficient corresponds to a \emph{wider} sheet of
paper. Furthermore, the width of the confidence interval (sheet of
paper) should be \emph{somehow} related to the amount of information
contained in the random sample, \(X_{1}\), \(X_{2}\), \ldots{},
\(X_{n}\). The following remarks makes these notions precise.

\begin{rem}
For a fixed confidence coefficient \(1-\alpha\), if \(n\) increases,
then the confidence interval gets \emph{SHORTER}.

For a fixed sample size \(n\), if \(1-\alpha\) increases, then the
confidence interval gets \emph{WIDER}.
\end{rem}

\label{exa-plant-one-samp-z-int} \textbf{Results from an Experiment on Plant
Growth.} The \texttt{PlantGrowth} data frame gives the results of an
experiment to measure plant yield (as measured by the weight of the
plant). We would like to a 95\% confidence interval for the mean weight
of the plants. Suppose that we know from prior research that the true
population standard deviation of the plant weights is \(0.7\) g.

The parameter of interest is \(\mu\), which represents the true mean
weight of the population of all plants of the particular species in
the study. We will first take a look at a stem-and-leaf display of the
data:



\begin{verbatim}
with(PlantGrowth, stem.leaf(weight))
\end{verbatim}

\begin{verbatim}
1 | 2: represents 1.2
 leaf unit: 0.1
            n: 30
   1     f | 5
         s | 
   2    3. | 8
   4    4* | 11
   5     t | 3
   8     f | 455
  10     s | 66
  13    4. | 889
  (4)   5* | 1111
  13     t | 2233
   9     f | 555
         s | 
   6    5. | 88
   4    6* | 011
   1     t | 3
\end{verbatim}

The data appear to be approximately normal with no extreme values. The
data come from a designed experiment, so it is reasonable to suppose
that the observations constitute a simple random sample of
weights. We know the population standard deviation
\(\sigma=0.70\) from prior research. We are going to use the
one-sample \(z\)-interval.

\begin{enumerate}
\item What is the parameter of interest? in the context of the problem.
\item Give a point estimate for \(\mu\).
\item What are the assumptions being made in the problem? Do they meet
the conditions of the interval?
\item Calculate the interval.
\item Draw the conclusion.
\end{enumerate}

\begin{rem}
What if \(\sigma\) is unknown? We instead use the interval
\begin{equation}
\overline{X}\pm z_{\alpha/2}\frac{S}{\sqrt{n}},
\end{equation}
where \(S\) is the sample standard deviation.
\begin{itemize}
\item If \(n\) is large, then \(\overline{X}\) will have an approximately
normal distribution regardless of the underlying population (by the
CLT) and \(S\) will be very close to the parameter \(\sigma\) (by
the SLLN); thus the above interval will have approximately
\(100(1-\alpha)\%\) confidence of covering \(\mu\).
\item If \(n\) is small, then
\begin{itemize}
\item If the underlying population is normal then we may replace
\(z_{\alpha/2}\) with \(t_{\alpha/2}(\mathtt{df}=n-1)\). The
resulting \(100(1-\alpha)\%\) confidence interval is
\begin{equation}
\label{eq-one-samp-t-int}
\overline{X}\pm t_{\alpha/2}(\mathtt{df}=n-1)\frac{S}{\sqrt{n}}.
\end{equation}
\item If the underlying population is not normal, but approximately
normal, then we may use the \(t\) interval, Equation
\eqref{eq-one-samp-t-int}. The interval will have approximately
\(100(1-\alpha)\%\) confidence of covering \(\mu\). However, if
the population is highly skewed or the data have outliers, then
we should ask a professional statistician for advice.
\end{itemize}
\end{itemize}
\end{rem}

The author learned of a handy acronym from AP Statistics Exam graders
that summarizes the important parts of confidence interval estimation,
which is PANIC: \emph{P}-arameter, \emph{A}-ssumptions, \emph{N}-ame, \emph{I}-nterval,
and \emph{C}-onclusion.
\begin{description}
\item[{Parameter:}] identify the parameter of interest with the proper
symbols. Write down what the parameter means in the
context of the problem.
\item[{Assumptions:}] list any assumptions made in the experiment. If
there are any other assumptions needed or that were
not checked, state what they are and why they are
important.
\item[{Name:}] choose a statistical procedure from your bag of tricks
based on the answers to the previous two parts. The
assumptions of the procedure you choose should match those
of the problem; if they do not match then either pick a
different procedure or openly admit that the results may
not be reliable. Write down any underlying formulas used.
\item[{Interval:}] calculate the interval from the sample data. This can
be done by hand but will more often be done with the
aid of a computer. Regardless of the method, all
calculations or code should be shown so that the entire
process is repeatable by a subsequent reader.
\item[{Conclusion:}] state the final results, using language in the
context of the problem. Include the appropriate
interpretation of the interval, making reference to
the confidence coefficient.
\end{description}

\begin{rem}
All of the above intervals for \(\mu\) were two-sided, but there are
also one-sided intervals for \(\mu\). They look like
\begin{equation}
\left[\overline{X}-z_{\alpha}\frac{\sigma}{\sqrt{n}},\ \infty\right)\quad \mbox{or}\quad \left(-\infty,\ \overline{X}+z_{\alpha}\frac{\sigma}{\sqrt{n}}\right]
\end{equation}
and satisfy
\begin{equation}
\mathbb{P}\left(\overline{X}-z_{\alpha}\frac{\sigma}{\sqrt{n}}\leq\mu\right)=1-\alpha\quad \mbox{and}\quad \mathbb{P}\left(\overline{X}+z_{\alpha}\frac{\sigma}{\sqrt{n}}\geq\mu\right)=1-\alpha.
\end{equation}
\end{rem}



Small sample, some data with \(X_{1}\), \(X_{2}\), \ldots{}, \(X_{n}\) an
\(SRS(n)\) from a
\(\mathsf{norm}(\mathtt{mean}=\mu,\,\mathtt{sd}=\sigma)\)
distribution.  PANIC

\subsection{How to do it with \(\mathsf{R}\)}
\label{sec-9-2-1}
We can do Example \ref{exa-plant-one-samp-z-int} with the following code.

\begin{verbatim}
temp <- with(PlantGrowth, z.test(weight, stdev = 0.7))
temp
\end{verbatim}

\begin{verbatim}

	One Sample z-test

data:  weight
z = 39.6942, n = 30.000, Std. Dev. = 0.700, Std. Dev. of the sample mean = 0.128,
p-value < 2.2e-16
alternative hypothesis: true mean is not equal to 0
95 percent confidence interval:
 4.822513 5.323487
sample estimates:
mean of weight 
         5.073
\end{verbatim}

The confidence interval bounds are shown in the sixth line down of the
output (please disregard all of the additional output information for
now -- we will use it in Chapter \ref{sec-10}). We can make the
plot for Figure \texttt{fig-plant-z-int-plot} with

\begin{verbatim}
plot(temp, "Conf")
\end{verbatim}

\section{Confidence Intervals for Differences of Means}
\label{sec-9-3}

Let \(X_{1}\), \(X_{2}\), \ldots{}, \(X_{n}\) be a \(SRS(n)\) from a
\(\mathsf{norm}(\mathtt{mean}=\mu_{X},\,\mathtt{sd}=\sigma_{X})\)
distribution and let \(Y_{1}\), \(Y_{2}\), \ldots{}, \(Y_{m}\) be a
\(SRS(m)\) from a
\(\mathsf{norm}(\mathtt{mean}=\mu_{Y},\,\mathtt{sd}=\sigma_{Y})\)
distribution. Further, assume that the \(X_{1}\), \(X_{2}\), \ldots{},
\(X_{n}\) sample is independent of the \(Y_{1}\), \(Y_{2}\), \ldots{},
\(Y_{m}\) sample.

Suppose that \(\sigma_{X}\) and \(\sigma_{Y}\) are known. We would
like a confidence interval for \(\mu_{X}-\mu_{Y}\). We know that
\begin{equation}
\overline{X}-\overline{Y}\sim\mathsf{norm}\left(\mathtt{mean}=\mu_{X}-\mu_{Y},\,\mathtt{sd}=\sqrt{\frac{\sigma_{X}^{2}}{n}+\frac{\sigma_{Y}^{2}}{m}}\right).
\end{equation}
Therefore, a \( 100(1-\alpha)\% \) confidence interval for
\(\mu_{X}-\mu_{Y}\) is given by
\begin{equation}
\label{eq-two-samp-mean-CI}
\left(\overline{X}-\overline{Y}\right)\pm z_{\alpha/2}\sqrt{\frac{\sigma_{X}^{2}}{n}+\frac{\sigma_{Y}^{2}}{m}}.
\end{equation}
Unfortunately, most of the time the values of \(\sigma_{X}\) and
\(\sigma_{Y}\) are unknown. This leads us to the following:
\begin{itemize}
\item If both sample sizes are large, then we may appeal to the CLT/SLLN
(see Section \ref{sec-8-3}) and substitute \(S_{X}^{2}\) and
\(S_{Y}^{2}\) for \(\sigma_{X}^{2}\) and \(\sigma_{Y}^{2}\) in the
interval \eqref{eq-two-samp-mean-CI}. The resulting confidence interval will
have approximately \(100(1-\alpha)\%\) confidence.
\item If one or more of the sample sizes is small then we are in trouble,
unless -the underlying populations are both normal and
\(\sigma_{X}=\sigma_{Y}\). In this case (setting
\(\sigma=\sigma_{X}=\sigma_{Y}\)),
\begin{equation}
\overline{X}-\overline{Y}\sim\mathsf{norm}\left(\mathtt{mean}=\mu_{X}-\mu_{Y},\,\mathtt{sd}=\sigma\sqrt{\frac{1}{n}+\frac{1}{m}}\right).
\end{equation} 
Now let
\begin{equation}
U=\frac{n-1}{\sigma^{2}}S_{X}^{2}+\frac{m-1}{\sigma^{2}}S_{Y}^{2}.
\end{equation}
Then by Exercise \ref{xca-sum-indep-chisq} we know that
\(U\sim\mathsf{chisq}(\mathtt{df}=n+m-2)\) and it is not a large
leap to believe that \(U\) is independent of
\(\overline{X}-\overline{Y}\); thus
\begin{equation}
T = \frac{Z}{\sqrt{\left.U\right/ (n+m-2)}}\sim\mathsf{t}(\mathtt{df}=n+m-2).
\end{equation}
But
\begin{align*}
T & =\frac{\frac{\overline{X}-\overline{Y}-(\mu_{X}-\mu_{Y})}{\sigma\sqrt{\frac{1}{n}+\frac{1}{m}}}}{\sqrt{\left.\frac{n-1}{\sigma^{2}}S_{X}^{2}+\frac{m-1}{\sigma^{2}}S_{Y}^{2}\right/ (n+m-2)}},\\
& =\frac{\overline{X}-\overline{Y}-(\mu_{X}-\mu_{Y})}{\sqrt{\left(\frac{1}{n}+\frac{1}{m}\right)\left(\frac{(n-1)S_{X}^{2}+(m-1)S_{Y}^{2}}{n+m-2}\right)}},\\
& \sim\mathsf{t}(\mathtt{df}=n+m-2).
\end{align*}
Therefore a \(100(1-\alpha)\%\) confidence interval for
\(\mu_{X}-\mu_{Y}\) is given by
\begin{equation}
\left(\overline{X}-\overline{Y}\right)\pm t_{\alpha/2}(\mathtt{df}=n+m-2)\, S_{p}\sqrt{\frac{1}{n}+\frac{1}{m}},
\end{equation}
where
\begin{equation}
S_{p}=\sqrt{\frac{(n-1)S_{X}^{2}+(m-1)S_{Y}^{2}}{n+m-2}}
\end{equation}
is called the "pooled" estimator of \(\sigma\).
\begin{itemize}
\item If one of the samples is small, and both underlying populations
are normal, but \(\sigma_{X}\neq\sigma_{Y}\), then we may use a
Welch (or Satterthwaite) approximation to the degrees of
freedom. See Welch \cite{Welch1947}, Satterthwaite
\cite{Satterthwaite1946}, or Neter \emph{et al} \cite{Neter1996}. The
idea is to use an interval of the form
\begin{equation}
\left(\overline{X}-\overline{Y}\right)\pm\mathsf{t}_{\alpha/2}(\mathtt{df}=r)\,\sqrt{\frac{S_{X}^{2}}{n}+\frac{S_{Y}^{2}}{m}},
\end{equation}
where the degrees of freedom \(r\) is chosen so that the
interval has nice statistical properties. It turns out that a
good choice for \(r\) is given by
\begin{equation}
r=\frac{\left(S_{X}^{2}/n+S_{Y}^{2}/m\right)^{2}}{\frac{1}{n-1}\left(S_{X}^{2}/n\right)^{2}+\frac{1}{m-1}\left(S_{Y}^{2}/m\right)^{2}},
\end{equation}
where we understand that \(r\) is rounded down to the nearest
integer. The resulting interval has approximately
\(100(1-\alpha)\%\) confidence.
\end{itemize}
\end{itemize}

\subsection{How to do it with \(\mathsf{R}\)}
\label{sec-9-3-1}

The basic function is \texttt{t.test} which has a \texttt{var.equal} argument that
may be set to \texttt{TRUE} or \texttt{FALSE}. The confidence interval is shown as
part of the output, although there is a lot of additional information
that is not needed until Chapter \ref{sec-10}.

There is not any specific functionality to handle the \(z\)-interval
for small samples, but if the samples are large then \texttt{t.test} with
\texttt{var.equal = FALSE} will be essentially the same thing. The standard
deviations are never (?) known in advance anyway so it does not really
matter in practice.

\section{Confidence Intervals for Proportions}
\label{sec-9-4}

We would like to know \(p\) which is the "proportion of
successes". For instance, \(p\) could be:
\begin{itemize}
\item the proportion of U.S. citizens that support Obama,
\item the proportion of smokers among adults age 18 or over,
\item the proportion of people worldwide infected by the H1N1 virus.
\end{itemize}

We are given an \(SRS(n)\) \(X_{1}\), \(X_{2}\), \ldots{}, \(X_{n}\)
distributed
\(\mathsf{binom}(\mathtt{size}=1,\,\mathtt{prob}=p)\). Recall from
Section \ref{sec-5-3} that the common mean of these variables
is \(\mathbb{E} X=p\) and the variance is
\(\mathbb{E}(X-p)^{2}=p(1-p)\). If we let \(Y=\sum X_{i}\), then from
Section \ref{sec-5-3} we know that
\(Y\sim\mathsf{binom}(\mathtt{size}=n,\,\mathtt{prob}=p)\) and that \[
\overline{X}=\frac{Y}{n}\mbox{ has }\mathbb{E}\overline{X}=p\mbox{ and
}\mathrm{Var}(\overline{X})=\frac{p(1-p)}{n}.  \] Thus if \(n\) is
large (here is the CLT) then an approximate \(100(1-\alpha)\%\)
confidence interval for \(p\) would be given by
\begin{equation}
\label{eq-ci-p-no-good}
\overline{X}\pm z_{\alpha/2}\sqrt{\frac{p(1-p)}{n}}.
\end{equation}
OOPS\ldots{}! Equation \eqref{eq-ci-p-no-good} is of no use to us because the
\underbar{unknown} parameter \(p\) is in the formula! (If we knew what
\(p\) was to plug in the formula then we would not need a confidence
interval in the first place.) There are two solutions to this problem.
\begin{enumerate}
\item Replace \(p\) with \(\hat{p}=\overline{X}\). Then an approximate
\(100(1-\alpha)\%\) confidence interval for \(p\) is given by
\begin{equation}
\hat{p}\pm z_{\alpha/2}\sqrt{\frac{\hat{p}(1-\hat{p})}{n}}.
\end{equation}
This approach is called the \emph{Wald interval} and is also known as
the \emph{asymptotic interval} because it appeals to the CLT for large
sample sizes.
\item Go back to first principles. Note that \[
   -z_{\alpha/2}\leq\frac{Y/n-p}{\sqrt{p(1-p)/n}}\leq z_{\alpha/2} \]
exactly when the function \(f\) defined by \[
   f(p)=\left(Y/n-p\right)^{2}-z_{\alpha/2}^{2}\frac{p(1-p)}{n} \]
satisfies \(f(p)\leq0\). But \(f\) is quadratic in \(p\) so its
graph is a parabola; it has two roots, and these roots form the
limits of the confidence interval. We can find them with the
quadratic formula (see Exercise \ref{xca-CI-quad-form}):
\begin{equation}
\left.\left[\left(\hat{p}+\frac{z_{\alpha/2}^{2}}{2n}\right)\pm z_{\alpha/2}\sqrt{\frac{\hat{p}(1-\hat{p})}{n}+\frac{z_{\alpha/2}^{2}}{(2n)^{2}}}\right]\right/ \left(1+\frac{z_{\alpha/2}^{2}}{n}\right)
\end{equation}
This approach is called the \emph{score interval} because it is based on
the inversion of the "Score test". See Chapter
\ref{sec-15}. It is also known as the \emph{Wilson
interval}; see Agresti \cite{Agresti2002}.
\end{enumerate}


For two proportions \(p_{1}\) and \(p_{2}\), we may collect
independent \(\mathsf{binom}(\mathtt{size}=1,\,\mathtt{prob}=p)\)
samples of size \(n_{1}\) and \(n_{2}\), respectively. Let \(Y_{1}\)
and \(Y_{2}\) denote the number of successes in the respective
samples.  We know that \[
\frac{Y_{1}}{n_{1}}\approx\mathsf{norm}\left(\mathtt{mean}=p_{1},\,\mathtt{sd}=\sqrt{\frac{p_{1}(1-p_{1})}{n_{1}}}\right)
\] and \[
\frac{Y_{2}}{n_{2}}\approx\mathsf{norm}\left(\mathtt{mean}=p_{2},\,\mathtt{sd}=\sqrt{\frac{p_{2}(1-p_{2})}{n_{2}}}\right)
\] so it stands to reason that an approximate \(100(1-\alpha)\%\)
confidence interval for \(p_{1}-p_{2}\) is given by
\begin{equation}
\left(\hat{p}_{1}-\hat{p}_{2}\right)\pm z_{\alpha/2}\sqrt{\frac{\hat{p}_{1}(1-\hat{p}_{1})}{n_{1}}+\frac{\hat{p}_{2}(1-\hat{p}_{2})}{n_{2}}},
\end{equation}
where \(\hat{p}_{1}=Y_{1}/n_{1}\) and \(\hat{p}_{2}=Y_{2}/n_{2}\).

\begin{rem}
When estimating a single proportion, one-sided intervals are sometimes
needed. They take the form
\begin{equation}
\left[0,\ \hat{p}+z_{\alpha/2}\sqrt{\frac{\hat{p}(1-\hat{p})}{n}}\right]
\end{equation}
or
\begin{equation}
\left[\hat{p}-z_{\alpha/2}\sqrt{\frac{\hat{p}(1-\hat{p})}{n}},\ 1\right]
\end{equation}
or in other words, we know in advance that the true proportion is
restricted to the interval \([0,1]\), so we can truncate our
confidence interval to those values on either side.
\end{rem}

\subsection{How to do it with \(\mathsf{R}\)}
\label{sec-9-4-1}

\begin{verbatim}
binconf(x = 7, n = 25, method = "asymptotic")
\end{verbatim}

\begin{verbatim}
:  PointEst     Lower     Upper
:      0.28 0.1039957 0.4560043
\end{verbatim}

\begin{verbatim}
binconf(x = 7, n = 25, method = "wilson")
\end{verbatim}

\begin{verbatim}
:  PointEst     Lower     Upper
:      0.28 0.1428385 0.4757661
\end{verbatim}

The default value of the \texttt{method} argument is \texttt{wilson}.  An alternate way is 
\begin{verbatim}
tab <- xtabs(~gender, data = RcmdrTestDrive)
prop.test(rbind(tab), conf.level = 0.95, correct = FALSE)
\end{verbatim}

\begin{verbatim}

	1-sample proportions test without continuity correction

data:  rbind(tab), null probability 0.5
X-squared = 4.6667, df = 1, p-value = 0.03075
alternative hypothesis: true p is not equal to 0.5
95 percent confidence interval:
 0.3447942 0.4922649
sample estimates:
        p 
0.4166667
\end{verbatim}

\begin{verbatim}
A <- as.data.frame(Titanic)
B <- with(A, untable(A, Freq))
\end{verbatim}

\section{Confidence Intervals for Variances}
\label{sec-9-5}

I am thinking one and two sample problems here.

\subsection{How to do it with \(\mathsf{R}\)}
\label{sec-9-5-1}

I am thinking about \texttt{sigma.test} in the \texttt{TeachingDemos} package
\cite{TeachingDemos} and \texttt{var.test} in base \(\mathsf{R}\) \cite{base}
here.

\section{Fitting Distributions}
\label{sec-9-6}

\subsection{How to do it with \(\mathsf{R}\)}
\label{sec-9-6-1}

I am thinking about \texttt{fitdistr} from the \texttt{MASS} package \cite{MASS}.

\section{Sample Size and Margin of Error}
\label{sec-9-7}

Sections \ref{sec-9-2} through \ref{sec-9-5} all began the same way: we were given the sample size
\(n\) and the confidence coefficient \(1-\alpha\), and our task was to
find a margin of error \(E\) so that \[ \hat{\theta}\pm E\mbox{ is a
}100(1-\alpha)\%\mbox{ confidence interval for }\theta.  \]

Some examples we saw were:
\begin{itemize}
\item \(E=z_{\alpha/2}\sigma/\sqrt{n}\), in the one-sample \(z\)-interval,
\item \(E=t_{\alpha/2}(\mathtt{df}=n+m-2)S_{p}\sqrt{n^{-1}+m^{-1}}\), in
the two-sample pooled \(t\)-interval.
\end{itemize}

We already know (we can see in the formulas above) that \(E\)
decreases as \(n\) increases. Now we would like to use this
information to our advantage: suppose that we have a fixed margin of
error \(E,\) say \(E=3\), and we want a \(100(1-\alpha)\%\) confidence
interval for \(\mu\). The question is: how big does \(n\) have to be?

For the case of a population mean the answer is easy: we set up an
equation and solve for \(n\).


Given a situation, given \(\sigma\), given \(E\), we would like to
know how big \(n\) has to be to ensure that \(\overline{X}\pm5\) is a
95\% confidence interval for \(\mu\).


\begin{rem}
Always round up any decimal values of \(n\), no matter how small the
decimal is. Another name for \(E\) is the "maximum error of the
estimate".
\end{rem}

For proportions, recall that the asymptotic formula to estimate \(p\)
was \[ \hat{p}\pm z_{\alpha/2}\sqrt{\frac{\hat{p}(1-\hat{p})}{n}}.  \]
Reasoning as above we would want
\begin{align}
\label{eq-samp-size-prop-ME}
E & =z_{\alpha/2}\sqrt{\frac{\hat{p}(1-\hat{p})}{n}},\mbox{ or}\\
n & =z_{\alpha/2}^{2}\frac{\hat{p}(1-\hat{p})}{E^{2}}.
\end{align}
OOPS! Recall that \(\hat{p}=Y/n\), which would put the variable \(n\)
on both sides of Equation \eqref{eq-samp-size-prop-ME}. Again, there are two
solutions to the problem.

\begin{enumerate}
\item If we have a good idea of what \(p\) is, say \(p^{\ast}\) then we
can plug it in to get
\begin{equation}
n=z_{\alpha/2}^{2}\frac{p^{\ast}(1-p^{\ast})}{E^{2}}.
\end{equation}
\item Even if we have no idea what \(p\) is, we do know from calculus
that \(p(1-p)\leq1/4\) because the function \(f(x)=x(1-x)\) is
quadratic (so its graph is a parabola which opens downward) with
maximum value attained at \(x=1/2\). Therefore, regardless of our
choice for \(p^{\ast}\) the sample size must satisfy
\begin{equation}
n=z_{\alpha/2}^{2}\frac{p^{\ast}(1-p^{\ast})}{E^{2}}\leq\frac{z_{\alpha/2}^{2}}{4E^{2}}.
\end{equation}
The quantity \(z_{\alpha/2}^{2}/4E^{2}\) is large enough to
guarantee \(100(1-\alpha)\%\) confidence.
\end{enumerate}


Proportion example.

\begin{rem}
For very small populations sometimes the value of \(n\) obtained from
the formula is too big. In this case we should use the hypergeometric
distribution for a sampling model rather than the binomial model. With
this modification the formulas change to the following: if \(N\)
denotes the population size then let
\begin{equation}
m=z_{\alpha/2}^{2}\frac{p^{\ast}(1-p^{\ast})}{E^{2}}
\end{equation}
and the sample size needed to ensure \(100(1-\alpha)\%\) confidence is
achieved is
\begin{equation}
n=\frac{m}{1+\frac{m-1}{N}}.
\end{equation}
If we do not have a good value for the estimate \(p^{\ast}\) then we may use \(p^{\ast}=1/2\).
\end{rem}

\subsection{How to do it with \(\mathsf{R}\)}
\label{sec-9-7-1}
I am thinking about \texttt{power.t.test}, \texttt{power.prop.test},
\texttt{power.anova.test}, and I am also thinking about \texttt{replicate}.

\section{Other Topics}
\label{sec-9-8}

Mention \texttt{mle} from the \texttt{stats4} package \cite{stats4}.

\newpage{}

\section{Exercises}
\label{sec-9-9}
\setcounter{thm}{0}

\begin{xca}
\label{xca-norm-mu-sig-MLE} Let \(X_{1}\), \(X_{2}\), \ldots{}, \(X_{n}\) be an
\(SRS(n)\) from a \(\mathsf{norm}(\mathtt{mean} = \mu, \, \mathtt{sd}
= \sigma)\) distribution. Find a two-dimensional MLE for
\(\theta=(\mu,\sigma)\).
\end{xca}

\begin{xca}
\label{xca-CI-quad-form} Find the upper and lower limits for the
confidence interval procedure by finding the roots of \(f\) defined by
\[ f(p)=\left(Y/n-p\right)^{2}-z_{\alpha/2}^{2}\frac{p(1-p)}{n}.  \]
You are going to need the quadratic formula.
\end{xca}
